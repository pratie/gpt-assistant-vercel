import pandas as pd
import numpy as np
from collections import Counter
import re

# Configuration
CSV_FILE = 'your_file.csv'  # Change to your file name
TEXT_COLUMN = 'User Justification Free Text'

def find_patterns_in_justifications(csv_file=CSV_FILE, text_column=TEXT_COLUMN):
    """
    Find patterns in user justifications
    """
    print("="*70)
    print("USER JUSTIFICATION PATTERN ANALYSIS")
    print("="*70)
    
    # Load data
    df = pd.read_csv(csv_file)
    
    # Get only non-empty justifications
    justifications = df[text_column].dropna().astype(str).tolist()
    justifications = [j for j in justifications if j.strip() and j.lower() != 'nan']
    
    print(f"\nAnalyzing {len(justifications)} user justifications...")
    print("-"*70)
    
    # 1. Most common complete justifications
    print("\n1. TOP 20 EXACT JUSTIFICATIONS (most repeated):")
    exact_counts = Counter(justifications)
    for i, (just, count) in enumerate(exact_counts.most_common(20), 1):
        if count > 1:  # Only show if appears more than once
            print(f"{i:2d}. [{count:3d}x] \"{just[:80]}{'...' if len(just) > 80 else ''}\"")
    
    # 2. Common words/phrases
    print("\n\n2. MOST COMMON WORDS:")
    all_text = ' '.join(justifications).lower()
    # Remove common words
    stop_words = {'the', 'a', 'an', 'is', 'was', 'are', 'were', 'been', 'be', 'have', 'has', 'had', 
                  'do', 'does', 'did', 'will', 'would', 'should', 'could', 'may', 'might',
                  'to', 'of', 'in', 'for', 'on', 'at', 'by', 'with', 'from', 'as', 'or', 'and'}
    
    words = [word for word in all_text.split() if word not in stop_words and len(word) > 2]
    word_counts = Counter(words).most_common(20)
    
    # Print in columns for better readability
    for i in range(0, len(word_counts[:20]), 2):
        if i+1 < len(word_counts):
            print(f"{i+1:2d}. '{word_counts[i][0]:<15}' ({word_counts[i][1]:>4})    "
                  f"{i+2:2d}. '{word_counts[i+1][0]:<15}' ({word_counts[i+1][1]:>4})")
        else:
            print(f"{i+1:2d}. '{word_counts[i][0]:<15}' ({word_counts[i][1]:>4})")
    
    # 3. Common 3-word phrases (skip 2-word, go straight to more meaningful 3-word)
    print("\n\n3. MOST COMMON 3-WORD PHRASES:")
    words_list = all_text.split()
    three_grams = []
    for i in range(len(words_list)-2):
        phrase = f"{words_list[i]} {words_list[i+1]} {words_list[i+2]}"
        three_grams.append(phrase)
    
    three_gram_counts = Counter(three_grams).most_common(30)
    for i, (phrase, count) in enumerate(three_gram_counts[:20], 1):
        if count > 2:
            print(f"{i:2d}. '{phrase}' - {count} times")
    
    # 4. Pattern-based categorization (THE MOST IMPORTANT PART)
    print("\n\n4. PATTERN-BASED CATEGORIES:")
    patterns = {
        'Format Issues': [r'format', r'formatting', r'should be', r'needs to be'],
        'Missing Information': [r'missing', r'not provided', r'no .* provided', r'not found', r'unable to', r'not extracted'],
        'Wrong Extraction': [r'extracted', r'wrong', r'incorrect', r'instead of', r'should be .* not'],
        'Name Issues': [r'name', r'first name', r'last name', r'patient name', r'hcp name', r'hanh'],
        'Phone Issues': [r'phone', r'telephone', r'contact number', r'cell', r'mobile'],
        'Date Issues': [r'date', r'dob', r'birth', r'appointment'],
        'Address Issues': [r'address', r'street', r'city', r'state', r'zip'],
        'Contact/Consent': [r'contact', r'consent', r'reporter', r'given'],
        'Classification/Merge': [r'classification', r'merge', r'category', r'combined'],
        'Partial Extraction': [r'partial', r'incomplete', r'only .* extracted', r'rest of']
    }
    
    category_counts = {cat: 0 for cat in patterns}
    category_examples = {cat: [] for cat in patterns}
    uncategorized = []
    
    for just in justifications:
        just_lower = just.lower()
        categorized = False
        for category, pattern_list in patterns.items():
            for pattern in pattern_list:
                if re.search(pattern, just_lower):
                    category_counts[category] += 1
                    if len(category_examples[category]) < 3:
                        category_examples[category].append(just)
                    categorized = True
                    break
            if categorized:
                break
        if not categorized:
            uncategorized.append(just)
    
    # Sort by count
    sorted_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
    
    print(f"\n{'Category':<25} {'Count':>8} {'Percent':>8}")
    print("-" * 45)
    for category, count in sorted_categories:
        if count > 0:
            print(f"{category:<25} {count:>8} {count/len(justifications)*100:>7.1f}%")
    
    print(f"\n{'Uncategorized':<25} {len(uncategorized):>8} {len(uncategorized)/len(justifications)*100:>7.1f}%")
    
    # Show examples for top categories
    print("\n\nTOP CATEGORY EXAMPLES:")
    for category, count in sorted_categories[:5]:
        if count > 0 and category_examples[category]:
            print(f"\n{category} ({count} cases):")
            for i, ex in enumerate(category_examples[category], 1):
                print(f"  {i}. \"{ex[:100]}...\"" if len(ex) > 100 else f"  {i}. \"{ex}\"")
    
    # 5. Actionable Summary
    print("\n\n5. ACTIONABLE SUMMARY:")
    print("="*70)
    
    total_categorized = sum(category_counts.values())
    print(f"Total justifications: {len(justifications)}")
    print(f"Categorized: {total_categorized} ({total_categorized/len(justifications)*100:.1f}%)")
    print(f"Uncategorized: {len(uncategorized)} ({len(uncategorized)/len(justifications)*100:.1f}%)")
    
    print("\nTOP 3 ISSUES TO FIX:")
    for i, (category, count) in enumerate(sorted_categories[:3], 1):
        if count > 0:
            print(f"\n{i}. {category} - {count} cases ({count/len(justifications)*100:.1f}%)")
            if 'Format' in category:
                print("   → Fix: Implement post-processing formatters")
            elif 'Missing' in category:
                print("   → Fix: Enhance extraction rules and validation")
            elif 'Wrong' in category:
                print("   → Fix: Improve prompt specificity and add examples")
            elif 'Name' in category:
                print("   → Fix: Add name parsing and validation rules")
            elif 'Phone' in category:
                print("   → Fix: Add phone number formatter and validator")
    
    # 6. Export results
    print("\n\nSAVING RESULTS...")
    
    # Create pattern analysis dataframe
    pattern_df = pd.DataFrame({'justification': justifications})
    
    # Add category flags
    for category, pattern_list in patterns.items():
        pattern_df[f'is_{category.lower().replace(" ", "_").replace("/", "_")}'] = pattern_df['justification'].apply(
            lambda x: any(re.search(p, x.lower()) for p in pattern_list)
        )
    
    pattern_df.to_csv('justification_patterns.csv', index=False)
    print("✓ Saved: justification_patterns.csv")
    
    # Save uncategorized for review
    if uncategorized:
        uncategorized_df = pd.DataFrame({'uncategorized_justification': uncategorized[:50]})  # Top 50
        uncategorized_df.to_csv('uncategorized_justifications.csv', index=False)
        print("✓ Saved: uncategorized_justifications.csv (top 50 for review)")
    
    return pattern_df

# Run the analysis
if __name__ == "__main__":
    pattern_df = find_patterns_in_justifications()
